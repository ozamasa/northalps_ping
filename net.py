#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from dotenv import load_dotenv
import os, platform, time
import gspread, requests
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ========= è¨­å®š =========
PING_WORKERS    = 100   # ä¸¦åˆ—pingæ•°ï¼ˆPiãªã‚‰80ã€œ128ç›®å®‰ï¼‰
NOTION_TIMEOUT  = 10    # Notion API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’
NOTION_BACKOFF  = 0.4   # Notion DBãƒšãƒ¼ã‚¸ãƒ³ã‚°æ™‚ã®å¾…ã¡(429å¯¾ç­–)

# ========= ENV =========
load_dotenv()
GOOGLE_CREDENTIALS_PATH = os.getenv("GOOGLE_CREDENTIALS_PATH")
SPREADSHEET_NAME       = os.getenv("SPREADSHEET_NAME")
NOTION_TOKEN           = os.getenv("NOTION_TOKEN")
NOTION_DB_ID           = os.getenv("NOTION_DATABASE_ID")      # IPä¸€è¦§DB
NOTION_LOGS_DB_ID      = os.getenv("NOTION_LOGS_DB_ID")       # ãƒ­ã‚°DBï¼ˆ1ã¤ï¼‰

NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28",
}

# ========= HTTP Sessionï¼ˆå®‰å®šï¼‹å†è©¦è¡Œï¼‰ =========
def create_session():
    s = requests.Session()
    retry = Retry(
        total=5, connect=5, read=5,
        backoff_factor=0.5,
        status_forcelist=(429, 500, 502, 503, 504),
        allowed_methods=frozenset(["GET", "POST", "PATCH"])
    )
    adapter = HTTPAdapter(max_retries=retry, pool_connections=20, pool_maxsize=50)
    s.mount("https://", adapter)
    s.mount("http://", adapter)
    return s

S = create_session()

# ========= Google Sheets =========
def gs_auth():
    scope = [
        "https://www.googleapis.com/auth/spreadsheets",
        "https://www.googleapis.com/auth/drive",
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_CREDENTIALS_PATH, scope)
    return gspread.authorize(creds)

def write_to_sheets_with_backup(data, sheet_name, log_sheet_name):
    """
    ãƒ¡ã‚¤ãƒ³ä¸Šæ›¸ã + æ—§ãƒ¡ã‚¤ãƒ³Båˆ—ã‚’ãƒ­ã‚°å³ç«¯ã¸é€€é¿ + ä»Šå›çµæœã‚‚ãƒ­ã‚°å³ç«¯ã¸è¿½åŠ 
    ï¼ˆãƒ¡ã‚¤ãƒ³ã¯å¯èª­ã®ãŸã‚ãƒ­ãƒ¼ã‚«ãƒ«æ™‚åˆ» "YYYY-MM-DD HH:MM:SS"ï¼‰
    """
    gc = gs_auth()
    ss = gc.open(SPREADSHEET_NAME)

    # ãƒ¡ã‚¤ãƒ³
    try:
        sheet = ss.worksheet(sheet_name)
    except gspread.exceptions.WorksheetNotFound:
        sheet = ss.add_worksheet(title=sheet_name, rows="300", cols="2")

    # ãƒ­ã‚°
    try:
        log_sheet = ss.worksheet(log_sheet_name)
    except gspread.exceptions.WorksheetNotFound:
        log_sheet = ss.add_worksheet(title=log_sheet_name, rows="300", cols="2")
        ips = [ip for ip, _ in data]
        log_sheet.update([["IP Address"] + ips], range_name="A1")

    # é€€é¿ï¼šç¾Båˆ—â†’ãƒ­ã‚°å³ç«¯
    try:
        current = sheet.get_all_values()
        if current and len(current) >= 2:
            prev_col = [row[1] if len(row) > 1 else "" for row in current[1:]]
            backup_col = [datetime.now().strftime("%Y-%m-%d %H:%M:%S")] + prev_col
            col_count = log_sheet.col_count
            if log_sheet.col_count < col_count + 1:
                log_sheet.add_cols((col_count + 1) - log_sheet.col_count)
            rng = gspread.utils.rowcol_to_a1(1, col_count + 1) + ":" + gspread.utils.rowcol_to_a1(len(backup_col), col_count + 1)
            log_sheet.update([[v] for v in backup_col], range_name=rng)
    except Exception:
        pass  # é€€é¿å¤±æ•—ã¯ç„¡è¦–

    # ãƒ¡ã‚¤ãƒ³ä¸Šæ›¸ã
    values = [["IP Address", "Timestamp"]] + data
    sheet.batch_update([{
        "range": f"A1:B{len(values)}",
        "values": values
    }])

    # ä»Šå›åˆ†ã‚’ãƒ­ã‚°å³ç«¯ã«è¿½åŠ 
    col_count = log_sheet.col_count
    run_col = [datetime.now().strftime("%Y-%m-%d %H:%M:%S")] + [ts for _, ts in data]
    if log_sheet.col_count < col_count + 1:
        log_sheet.add_cols((col_count + 1) - log_sheet.col_count)
    rng = gspread.utils.rowcol_to_a1(1, col_count + 1) + ":" + gspread.utils.rowcol_to_a1(len(run_col), col_count + 1)
    log_sheet.update([[v] for v in run_col], range_name=rng)

# ========= Ping =========
def ping_ip(ip):
    sys = platform.system().lower()
    if sys == "windows":
        cmd = f"ping -n 1 -w 1000 {ip} > nul"
    elif sys == "darwin":
        cmd = f"ping -c 1 -t 1 {ip} > /dev/null 2>&1"
    else:
        cmd = f"ping -c 1 -w 1 {ip} > /dev/null 2>&1"
    return os.system(cmd) == 0

def ping_subnet(prefix, workers=PING_WORKERS):
    ips = [f"{prefix}{i}" for i in range(1, 255)]
    # Notionå‘ã‘ã¯ ISOï¼ˆdateå‹ç”¨ï¼‰ã€Sheetså‘ã‘ã¯å¯èª­
    ts_iso = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")
    ts_human = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    results = []            # [[ip, human_ts or ""]]
    results_iso = []        # [[ip, iso_ts or ""]]
    with ThreadPoolExecutor(max_workers=workers) as ex:
        futs = {ex.submit(ping_ip, ip): ip for ip in ips}
        for fut in as_completed(futs):
            ip = futs[fut]
            ok = fut.result()
            results.append([ip, ts_human if ok else ""])
            results_iso.append([ip, ts_iso if ok else ""])
    results.sort(key=lambda x: int(x[0].split(".")[-1]))
    results_iso.sort(key=lambda x: int(x[0].split(".")[-1]))
    return results, results_iso

# ========= Notionï¼ˆå·®åˆ†åˆ¤å®šã¯ DB query ã®ã¿ã§ï¼‰ =========
def fetch_pages_map(db_id):
    """ip -> {'id': page_id, 'ts': 'ISO or ""', 'status': 'æ¥ç¶š/æ¥ç¶šä¸å¯'}"""
    page_map = {}
    url = f"https://api.notion.com/v1/databases/{db_id}/query"
    payload = {"page_size": 100}
    while True:
        r = S.post(url, headers=NOTION_HEADERS, json=payload, timeout=NOTION_TIMEOUT)
        r.raise_for_status()
        data = r.json()
        for row in data.get("results", []):
            props = row.get("properties", {})
            title = props.get("IP Address", {}).get("title", [])
            ip = title[0]["text"]["content"] if title else None
            if not ip:
                continue
            # dateå‹ã® start ã‚’æ‹¾ã†ï¼ˆç„¡ã‘ã‚Œã° ""ï¼‰
            ts = ""
            try:
                ts = (props.get("Timestamp", {}) or {}).get("date", {}).get("start", "") or ""
            except Exception:
                pass
            status = props.get("Status", {}).get("select", {}).get("name", "")
            page_map[ip] = {"id": row["id"], "ts": ts, "status": status}
        if not data.get("has_more"):
            break
        payload["start_cursor"] = data.get("next_cursor")
        time.sleep(NOTION_BACKOFF)
    return page_map

# ãƒ­ã‚°DBã®ã‚¹ã‚­ãƒ¼ãƒï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼‰
def get_db_properties(db_id):
    try:
        r = S.get(f"https://api.notion.com/v1/databases/{db_id}", headers=NOTION_HEADERS, timeout=NOTION_TIMEOUT)
        r.raise_for_status()
        return r.json().get("properties", {})
    except requests.exceptions.RequestException:
        return {}

LOG_DB_PROPS = get_db_properties(NOTION_LOGS_DB_ID) if NOTION_LOGS_DB_ID else {}

def has_prop(props, name, type_):
    p = props.get(name)
    return p and p.get("type") == type_

def create_log_record(ip, ts_iso, status_name, network_prefix=None):
    """ãƒ­ã‚°DBã¸1è¡Œï¼ˆTimestamp ã¯ dateå‹ã€æœªæ¥ç¶šã¯date Noneï¼‰"""
    if not NOTION_LOGS_DB_ID:
        return

    props = {}
    if has_prop(LOG_DB_PROPS, "IP Address", "title"):
        props["IP Address"] = {"title": [{"text": {"content": ip}}]}
    else:
        # title ãŒç„¡ã„DBã«ã¯ãƒšãƒ¼ã‚¸ä½œã‚Œãªã„
        return

    if has_prop(LOG_DB_PROPS, "Status", "select"):
        props["Status"] = {"select": {"name": status_name}}

    if has_prop(LOG_DB_PROPS, "Timestamp", "date"):
        props["Timestamp"] = {"date": {"start": ts_iso}} if ts_iso else {"date": None}

    if network_prefix and has_prop(LOG_DB_PROPS, "Network", "select"):
        props["Network"] = {"select": {"name": network_prefix}}

    payload = {"parent": {"database_id": NOTION_LOGS_DB_ID}, "properties": props}
    try:
        S.post("https://api.notion.com/v1/pages",
               headers=NOTION_HEADERS, json=payload, timeout=NOTION_TIMEOUT)
    except requests.exceptions.RequestException:
        pass  # ãƒ­ã‚°å¤±æ•—ã¯ç„¡è¦–

def upsert_notion(data_iso, db_id, network_prefix=None):
    """
    data_iso: [[ip, iso_ts or ""]]
    main DB ã¯ Timestamp(dateå‹) ã¨ Status(select) ã‚’å·®åˆ†æ™‚ã®ã¿æ›´æ–°
    ãƒ­ã‚°DBã¯æ¯å›1è¡Œè¿½åŠ 
    """
    try:
        page_map = fetch_pages_map(db_id)
    except requests.exceptions.RequestException as e:
        print(f"âŒ Notion DB query å¤±æ•—: {e}")
        return

    for ip, ts_iso in data_iso:
        status_name = "æ¥ç¶š" if ts_iso else "æ¥ç¶šä¸å¯"
        pm = page_map.get(ip)

        if not pm:
            # æ–°è¦ä½œæˆ
            create_payload = {
                "parent": {"database_id": db_id},
                "properties": {
                    "IP Address": {"title": [{"text": {"content": ip}}]},
                    "Timestamp": {"date": {"start": ts_iso}} if ts_iso else {"date": None},
                    "Status": {"select": {"name": status_name}}
                }
            }
            try:
                S.post("https://api.notion.com/v1/pages",
                       headers=NOTION_HEADERS, json=create_payload, timeout=NOTION_TIMEOUT)
            except requests.exceptions.RequestException as e:
                print(f"âŒ Notionä½œæˆå¤±æ•—: {ip} - {e}")
            create_log_record(ip, ts_iso, status_name, network_prefix)
            time.sleep(0.02)
            continue

        # å·®åˆ†ãŒã‚ã‚‹æ™‚ã ã‘æ›´æ–°
        if pm.get("ts", "") != (ts_iso or "") or pm.get("status", "") != status_name:
            try:
                S.patch(
                    f"https://api.notion.com/v1/pages/{pm['id']}",
                    headers=NOTION_HEADERS,
                    json={"properties": {
                        "Timestamp": {"date": {"start": ts_iso}} if ts_iso else {"date": None},
                        "Status": {"select": {"name": status_name}}
                    }},
                    timeout=NOTION_TIMEOUT
                )
            except requests.exceptions.RequestException as e:
                print(f"âŒ Notionæ›´æ–°å¤±æ•—: {ip} - {e}")

        # ãƒ­ã‚°ã¯æ¯å›1è¡Œ
        create_log_record(ip, ts_iso, status_name, network_prefix)
        time.sleep(0.02)  # 429å¯¾ç­–ã®è»½ã„é–“å¼•ã

# ========= Main =========
if __name__ == "__main__":
    prefixes = ["192.168.10.", "192.168.80."]

    for prefix in prefixes:
        # 1) ä¸¦åˆ— pingï¼ˆSheetsç”¨ã¨Notionç”¨ã®æ™‚åˆ»ã‚’ç”¨æ„ï¼‰
        results_human, results_iso = ping_subnet(prefix, workers=PING_WORKERS)
        alive = sum(1 for _, ts in results_iso if ts)
        print(f"ğŸ“¡ {prefix} Alive: {alive}/254")

        # 2) Sheetsï¼šé€€é¿â†’ãƒ¡ã‚¤ãƒ³æ›´æ–°â†’ãƒ­ã‚°åˆ—è¿½åŠ 
        sheet = prefix.replace(".", "_")
        write_to_sheets_with_backup(results_human, sheet, f"{sheet}_log")

        # 3) Notionï¼šå·®åˆ†ã®ã¿æ›´æ–° + ãƒ­ã‚°DBã¸æ¯å›1è¡Œï¼ˆTimestampã¯dateå‹ï¼‰
        upsert_notion(results_iso, NOTION_DB_ID, network_prefix=prefix)

    print("ğŸ å…¨å‡¦ç†å®Œäº†ï¼")